{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1a8a17a-2b6d-45b1-87ac-99821ed56698",
   "metadata": {},
   "source": [
    "# PLOTS FOR PAPER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c0eada-65b3-4c04-9525-6f18832de3aa",
   "metadata": {},
   "source": [
    "This notebook creates the plots for the paper. Figures are generated as PDFs in the directory cn.PLOT_DIR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd24ba31-b89f-42d9-b5f1-d7a886ee093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pySubnetSB.constants as cn\n",
    "from pySubnetSB.network import Network\n",
    "from pySubnetSB.constraint_benchmark import ConstraintBenchmark\n",
    "from pySubnetSB.identity_hash_benchmark import IdentityHashBenchmark\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tellurium as te\n",
    "from typing import List, Optional, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5c2d81-1b81-401b-b3cb-a8c3714cb858",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_ALL = False  # Do all of the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da91745-1abb-47fa-92ca-2b6d69636bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_TITLE_FONT_INCREMENT = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf89105-63e1-4452-b23c-11dd6447b87a",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2eb53e-de0d-4274-acdd-a9f54a8212a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_STRONG_DF = pd.read_csv(cn.FULL_BIOMODELS_STRONG_PATH).sort_values([cn.FINDER_REFERENCE_NAME, cn.FINDER_TARGET_NAME])\n",
    "STRONG_DF = pd.read_csv(cn.SUBNET_BIOMODELS_STRONG_PATH).sort_values([cn.FINDER_REFERENCE_NAME, cn.FINDER_TARGET_NAME])\n",
    "STRONG_DF = STRONG_DF.reset_index()\n",
    "FULL_WEAK_DF = pd.read_csv(cn.FULL_BIOMODELS_WEAK_PATH).sort_values([cn.FINDER_REFERENCE_NAME, cn.FINDER_TARGET_NAME])\n",
    "WEAK_DF = pd.read_csv(cn.SUBNET_BIOMODELS_WEAK_PATH).sort_values([cn.FINDER_REFERENCE_NAME, cn.FINDER_TARGET_NAME])\n",
    "WEAK_DF = WEAK_DF.reset_index()\n",
    "SUMMARY_DF = pd.read_csv(cn.BIOMODELS_SUMMARY_PATH).sort_values(cn.D_MODEL_NAME)\n",
    "SUMMARY_DF = SUMMARY_DF.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1838ef-aa25-4bcd-af39-2f2fa75400b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "STRONG_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16521b24-703c-4ad1-9add-3bb8b809dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEAK_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e465fd7-e41a-4ae7-8574-ae5a1b3e9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_DF.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3362055f-8172-448d-b27f-a2afea5897b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeMergeColumnName(column:str, is_reference:bool=True)->str:\n",
    "    \"\"\"\n",
    "    Creates column names for merged result of subnet dataframe with summary dataframe.\n",
    "    \"\"\"\n",
    "    if is_reference:\n",
    "        suffix = \"_reference\"\n",
    "    else:\n",
    "        suffix = \"_induced\"\n",
    "    return column + \"_reference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfca9914-3a55-4d21-a6cc-693aefecceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the subnet information with the reference num_reaction, num_species\n",
    "def mergeWithSummary(subnet_df:pd.DataFrame=STRONG_DF)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Augment the subnet dataframe with summary information for reference network.\n",
    "    \"\"\"\n",
    "    df = subnet_df.merge(SUMMARY_DF, right_on='model_name', left_on='reference_name',\n",
    "                        suffixes=[\"_induced\", \"_reference\"])\n",
    "    # Clean up the DataFrame\n",
    "    df = df.reset_index()\n",
    "    del df['index']\n",
    "    drops = df['reference_name'] == 'something'\n",
    "    df = df[~drops]\n",
    "    # Eliminate duplicate rows\n",
    "    df['key'] = df['reference_name'] + \"_\" + df['target_name']  # key for an entry\n",
    "    keys = list(df['key'])\n",
    "    duplicate_keys = list(set([k for k in keys if keys.count(k) > 1]))\n",
    "    for duplicate_key in duplicate_keys:\n",
    "        duplicate_df = df [ df['key'] == duplicate_key]\n",
    "        indices = list(duplicate_df.index)\n",
    "        df = df.drop(indices[1:])\n",
    "    # Final cleanup\n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "#\n",
    "df = mergeWithSummary()\n",
    "assert(len([c for c in df.columns if \"_reference\" in c]) > 0)\n",
    "assert(len([c for c in df.columns if \"_induced\" in c]) > 0)\n",
    "assert(len(df) <= len(STRONG_DF))\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f067f01-e300-4e4f-923b-03b307c77ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "STRONG_DF = mergeWithSummary(subnet_df=STRONG_DF)\n",
    "WEAK_DF = mergeWithSummary(subnet_df=WEAK_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033d02c3-a8ff-40f9-97ed-68e70735eaed",
   "metadata": {},
   "source": [
    "## Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07558c1-8c64-4694-8750-069d22f44b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkSubnetDuplicates(subnet_df:pd.DataFrame, is_fix:bool=True)->pd.DataFrame:\n",
    "    df = subnet_df.copy()\n",
    "    keys = [r + \"_\" + t for r, t in zip(df[cn.FINDER_REFERENCE_NAME], df[cn.FINDER_TARGET_NAME])]\n",
    "    df['key'] = keys\n",
    "    count_dct = {k: keys.count(k) for k in keys}\n",
    "    if len(keys) > len(set(keys)):\n",
    "        for key in[k for k in set(keys) if count_dct[k] > 1]:\n",
    "            if is_fix:\n",
    "                sel = df['key'] == key\n",
    "                idxs = df.index[sel]\n",
    "                df = df.drop(idxs[:-1])\n",
    "            print(key + \"\\n\")\n",
    "            print(df[df['key'] == key])\n",
    "    else:\n",
    "        print(\"No duplicates!\")\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a45903-d5e1-479b-a7c7-bb866e68b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*** WEAK\")\n",
    "WEAK_DF = checkSubnetDuplicates(WEAK_DF, is_fix=True)\n",
    "checkSubnetDuplicates(WEAK_DF, is_fix=False)\n",
    "#\n",
    "print(\"\\n***STRONG\")\n",
    "STRONG_DF = checkSubnetDuplicates(STRONG_DF, is_fix=True)\n",
    "checkSubnetDuplicates(STRONG_DF, is_fix=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884dade6-5613-4201-b295-4c1fac3ae381",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285efb2b-f9c3-47fc-8abd-1a6a783a6aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTestDataFrame():\n",
    "    df = pd.DataFrame({'reference_name': [0, 1, 1, 2, 2, 2], 'target_name': [0, 1, 1, 2, 2, 2]})\n",
    "    return df.astype(str)\n",
    "TEST_NUM_DUPLICATE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d60abcd-731a-47d4-8e29-2925e51fab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeAntimony(model_name:str, is_reference:bool=True, subnet_df:pd.DataFrame=STRONG_DF, is_roadrunner_loadable:bool=False):\n",
    "    \"\"\"\n",
    "    Transforms the string in a \"network\" cell into an antimony model\n",
    "    \"\"\"\n",
    "    if is_reference:\n",
    "        name_col = 'reference_name'\n",
    "        network_col = 'reference_network'\n",
    "    else:\n",
    "        name_col = 'target_name'\n",
    "        network_col = 'induced_network'\n",
    "    models =  subnet_df[subnet_df[name_col] == model_name][network_col].values\n",
    "    if len(models) == 0:\n",
    "        return None\n",
    "    model = models[0]\n",
    "    if is_roadrunner_loadable:\n",
    "        pos = model.index('tions\\n')\n",
    "        model = model[pos+7:]\n",
    "        model = model.replace('\\n', ';1\\n')\n",
    "        model += \";1;\"\n",
    "    return model\n",
    "\n",
    "# TESTS\n",
    "model = makeAntimony('BIOMD0000000224', is_roadrunner_loadable=True)\n",
    "rr = te.loada(model)\n",
    "model = makeAntimony('BIOMD0000000030')\n",
    "assert(model is None)\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e870c9e9-9997-4e6b-9fee-fe66649bf768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractBiomodelNum(stg:str)->int:\n",
    "    \"\"\"\n",
    "    Extracts the number from the biomodels name.\n",
    "    \"\"\"\n",
    "    substg = stg[5:]\n",
    "    pos = np.min([n if c != '0' else 1000 for n, c in enumerate(substg)])\n",
    "    try:\n",
    "        result = int(substg[pos:])\n",
    "    except:\n",
    "        result = None\n",
    "    return result\n",
    "\n",
    "# TESTS\n",
    "num = extractBiomodelNum('BIOMD0000000030')\n",
    "assert(num == 30)\n",
    "num = extractBiomodelNum('BIOMD0000002030')\n",
    "assert(num == 2030)\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fda729-7fd6-4b6f-b6a4-3a7873aa270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkDuplicates(df:pd.DataFrame, is_print:bool=True)->list:\n",
    "    \"\"\"\n",
    "    Checks if elements are duplicated\n",
    "    \"\"\"\n",
    "    keys = list(df['reference_name'] + df['target_name'])\n",
    "    duplicates = []\n",
    "    if len(keys) > len(set(keys)):\n",
    "        duplicates = [k for k in keys if keys.count(k) > 1]\n",
    "        if is_print:\n",
    "            print(f\"**Duplicate entries: {duplicates}\")\n",
    "    else:\n",
    "        if is_print:\n",
    "            print(\"**No duplicate entries\")\n",
    "    return duplicates\n",
    "\n",
    "count = len(checkDuplicates(makeTestDataFrame(), is_print=False))\n",
    "assert(count == TEST_NUM_DUPLICATE)\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef241846-d661-4e62-8235-79c1f9cd1914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDuplicates(df:pd.DataFrame)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove rows where the reference_name + target_name is duplicated.\n",
    "\n",
    "    Args:\n",
    "        df: dataframe procesed\n",
    "\n",
    "    Returns:\n",
    "        DataFrame w/o duplicates\n",
    "    \"\"\"\n",
    "    keys = np.array(df['reference_name'].astype(str) + df['target_name'].astype(str))\n",
    "    all_positions = np.array(range(len(keys)))\n",
    "    drop_idxs = []\n",
    "    for key in set(keys):\n",
    "        key_positions = all_positions[keys == key]\n",
    "        drop_idxs.extend(key_positions[:-1])\n",
    "    result_df = df.drop(drop_idxs)\n",
    "    return result_df\n",
    "\n",
    "# TESTS\n",
    "df = makeTestDataFrame()\n",
    "result_df = removeDuplicates(df)\n",
    "assert(len(result_df) == 3)\n",
    "print(\"OK!\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a1053-2e00-4829-8c9a-a3108677fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTargetNames(reference_name:str, subnet_df:pd.DataFrame=STRONG_DF)->List[str]:\n",
    "    \"\"\"\n",
    "    Gets the list of target names for the reference, if any.\n",
    "\n",
    "    Args:\n",
    "       reference_name: str\n",
    "\n",
    "    Returns:\n",
    "       list-str\n",
    "    \"\"\"\n",
    "    sel = subnet_df[\"reference_name\"] == reference_name\n",
    "    if np.sum(sel) == 0:\n",
    "        return None\n",
    "    target_names = subnet_df[sel][\"target_name\"].values\n",
    "    return target_names\n",
    "\n",
    "# Tests\n",
    "names = getTargetNames(\"BIOMD0000000224\")\n",
    "assert(len(names) > 0)\n",
    "names = getTargetNames(\"BIOMD000000022x\")\n",
    "assert(names is None)\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb4ec9-79c5-408e-bed2-adb6da2bf107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateLog10Probability(prob:Union[float, np.ndarray], min_prob=1e-5)->np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates -Log10 of probabilities\n",
    "    \"\"\"\n",
    "    if isinstance(prob, float) or isinstance(prob, int):\n",
    "        new_prob = max(prob, min_prob)\n",
    "    else:\n",
    "        new_prob = np.array([max(v, min_prob) for v in prob])\n",
    "    return -np.log10(new_prob)\n",
    "        \n",
    "# Test\n",
    "result = calculateLog10Probability(0.4)\n",
    "result = calculateLog10Probability(0)\n",
    "assert(result == 5)\n",
    "#\n",
    "result = calculateLog10Probability([0.5, 0])\n",
    "assert(result[1] == 5)\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b21441-27b5-40c2-bc2a-ef17f6a975f0",
   "metadata": {},
   "source": [
    "# Scalable Identity Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8affce16-b50c-474c-a9fd-f548ed7dda52",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_ALL:\n",
    "    SCALABLE_IDENTITY_DETECTION_PATH = os.path.join(cn.AUXILIARY_DATA_DIR, \"scalable_identity_detection.csv\")\n",
    "    species_nums = range(2, 22, 2)\n",
    "    reaction_nums = range(2, 22, 2)\n",
    "    benchmark = IdentityHashBenchmark(species_nums, reaction_nums, num_network=1000)\n",
    "    if not os.path.isfile(SCALABLE_IDENTITY_DETECTION_PATH):\n",
    "        df = benchmark.plotHashStatistics(font_size=14, is_plot=False)\n",
    "        df.to_csv(SCALABLE_IDENTITY_DETECTION_PATH)\n",
    "    else:\n",
    "        _ = benchmark.plotHashStatistics(font_size=14, hash_statistics_df=df, is_plot=False)\n",
    "    path = os.path.join(cn.PLOT_DIR, \"scalable_identity_detection.pdf\")\n",
    "    plt.savefig(path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef83ee7b-e3cb-4fd0-9d60-f432555e58af",
   "metadata": {},
   "source": [
    "# Scalable Subnet Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a13f71b-5391-4b43-a895-f440869f010e",
   "metadata": {},
   "source": [
    "## Evaluation of constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2182a-11fb-469b-b9ef-0d062b691739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if PLOT_ALL:\n",
    "if True:\n",
    "    reference_size = 20\n",
    "    target_size = 100\n",
    "    fill_size = target_size - reference_size\n",
    "    benchmark = ConstraintBenchmark(reference_size, fill_size=fill_size, num_iteration=1000)\n",
    "    _ = benchmark.plotCompareConstraints(is_subnet=True, is_plot=False, font_size=18)\n",
    "    path = os.path.join(cn.PLOT_DIR, \"evaluate_constraints.pdf\")\n",
    "    plt.savefig(path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3efd34b-3528-4ce2-8392-5f8dbe7ca9bc",
   "metadata": {},
   "source": [
    "## Effectiveness of constratins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26323f-ad51-48f3-ba6d-5d2c777429cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine figures\n",
    "if PLOT_ALL:\n",
    "    from matplotlib.gridspec import GridSpec\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    gs = GridSpec(1, 32, figure=fig)\n",
    "    ax1 = fig.add_subplot(gs[:, 0:10])\n",
    "    ax2 = fig.add_subplot(gs[:, 10:20])\n",
    "    ax3 = fig.add_subplot(gs[:, 20:30])\n",
    "    ax4 = fig.add_subplot(gs[:, 31:32])\n",
    "    num_iteration = 1000\n",
    "    font_size = 20\n",
    "    num_digit = 0\n",
    "    _ = ConstraintBenchmark.plotHeatmap(range(4, 24, 4), range(10, 110, 10), percentile=50, font_size=font_size,\n",
    "         ax=ax1, is_no_constraint=True, num_iteration=1, is_cbar=False, title=\"No constraint\", is_plot=False,\n",
    "        num_digit=num_digit)\n",
    "    _ = ConstraintBenchmark.plotHeatmap(range(4, 24, 4), range(10, 110, 10), percentile=50, is_contains_reference=True,\n",
    "        font_size=font_size, num_digit=num_digit,\n",
    "        ax=ax2, num_iteration=num_iteration, is_cbar=False, is_plot=False, title=\"constraint w/subnet\")\n",
    "    _ = ConstraintBenchmark.plotHeatmap(range(4, 24, 4), range(10, 110, 10), percentile=50, is_contains_reference=False,\n",
    "        font_size=font_size, num_digit=num_digit,\n",
    "        ax=ax3, num_iteration=num_iteration, is_cbar=False, is_plot=False, title=\"constraint w/o subnet\")\n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=15)\n",
    "    cbar = fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap='Reds'),\n",
    "                 cax=ax4, orientation='vertical', label='log10 number of assignment pairs')\n",
    "    #ax4.set_label(\"log10 number of assignment pairs\", size=font_size)\n",
    "    cbar.set_label(label='log10 number of assignment pairs',size=font_size)\n",
    "    ax2.set_ylabel(\"\")\n",
    "    ax2.set_yticklabels([])\n",
    "    ax3.set_ylabel(\"\")\n",
    "    ax3.set_yticklabels([])\n",
    "    path = os.path.join(cn.PLOT_DIR, \"scalable_subnet_discovery.pdf\")\n",
    "    plt.savefig(path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50fc6ed-adf8-4034-bac2-b7bdd6cbbc2e",
   "metadata": {},
   "source": [
    "# Statistical significance of a network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429fe2aa-cba7-496e-9415-7e8dfe47359c",
   "metadata": {},
   "source": [
    "Calculation of the POC of networks with weak and strong identity to the BioModels reference networks (those with number reactions <= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38768421-3210-4c8c-b6f6-5ef3004ecf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotModelPOC(is_strong:bool=True, is_plot:bool=True, font_size=16):\n",
    "    if is_strong:\n",
    "        column = cn.D_PROBABILITY_OF_OCCURRENCE_STRONG\n",
    "        adjective = 'Strong'\n",
    "    else:\n",
    "        column = cn.D_PROBABILITY_OF_OCCURRENCE_WEAK\n",
    "        adjective = 'Weak'\n",
    "    pivot_df = SUMMARY_DF.pivot_table(values=column,\n",
    "                    index=cn.D_NUM_REACTION, columns=cn.D_NUM_SPECIES, aggfunc='median')\n",
    "    pivot_df = pivot_df.map(lambda x: calculateLog10Probability(x))\n",
    "    pivot_df.sort_index(level=0, ascending=False, inplace=True)\n",
    "    if is_plot:\n",
    "        sns.heatmap(pivot_df, annot=True, fmt=\"1.0f\", cmap=\"coolwarm\", vmin=0, vmax=5,\n",
    "              annot_kws={'size': font_size},\n",
    "              cbar_kws={'label': '-log10 Probability of occurrence'})\n",
    "        #plt.title(f\"{adjective} Identity\")\n",
    "        plt.xlabel(\"number of species\", size=font_size)\n",
    "        plt.ylabel(\"number of reactions\", size=font_size)\n",
    "# Test\n",
    "plotModelPOC(is_strong=True, is_plot=False)\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2f818-94b0-4669-8c63-208b87c82794",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_ALL:\n",
    "    plotModelPOC(is_strong=True)\n",
    "    path = os.path.join(cn.PLOT_DIR, \"strong_identity_significance_reference_networks.pdf\")\n",
    "    plt.savefig(path)\n",
    "    # Little difference between strong and weak identity\n",
    "    #plt.figure()\n",
    "    #plotModelPOC(is_strong=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01aec24-dc38-4d3a-9de8-5ba0a200d428",
   "metadata": {},
   "source": [
    "# Subnet Discovery in BioModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708fb676-e787-436a-9591-0a502de0d52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmapCount(induced_df, title:str=\"\", is_plot:bool=True, is_count:bool=True, ax=None,\n",
    "        network_column=cn.FINDER_REFERENCE_NAME, vmax:int=-1, fmt=\"\", font_size=8):\n",
    "    \"\"\"\n",
    "    Counts occurrences of reference networks in induced_df or the number of induced networks.\n",
    "    Args:\n",
    "        is_count (bool): count distinct values of network_count; if False, calculate ratio of all occurrences to distinct\n",
    "    \"\"\"\n",
    "    # Calculate count of networks\n",
    "    count_df = induced_df.copy()\n",
    "    count_df = count_df[[network_column, cn.D_NUM_SPECIES, cn.D_NUM_REACTION]]\n",
    "    count_df = count_df.drop_duplicates()\n",
    "    #\n",
    "    if is_count:\n",
    "        # Count sizes of reference networks\n",
    "        plot_df = count_df\n",
    "        bar_label = 'count'\n",
    "        if len(fmt) == 0:\n",
    "            fmt=\"1.0f\"\n",
    "        if vmax < 0:\n",
    "            vmax = 10\n",
    "    else:\n",
    "        # Count occurrence of induced networks\n",
    "        plot_df = induced_df\n",
    "        bar_label = 'ratio'\n",
    "        if len(fmt) == 0:\n",
    "            fmt=\"1.1f\"\n",
    "        if vmax < 0:\n",
    "            vmax = 100\n",
    "    network_ser = count_df.groupby([cn.D_NUM_SPECIES, cn.D_NUM_REACTION]).count()[network_column]\n",
    "    induced_ser = induced_df.groupby([cn.D_NUM_SPECIES, cn.D_NUM_REACTION]).count()[network_column]\n",
    "    if is_count:\n",
    "        plot_ser = network_ser\n",
    "    else:\n",
    "        plot_ser = induced_ser/network_ser\n",
    "    num_species = [x[0] for x in network_ser.index]\n",
    "    num_reactions = [x[1] for x in network_ser.index]\n",
    "    df = pd.DataFrame({cn.D_NUM_SPECIES: num_species, cn.D_NUM_REACTION: num_reactions, 'count': plot_ser.values})\n",
    "    pivot_df = df.pivot_table(values='count', index=cn.D_NUM_REACTION, columns=cn.D_NUM_SPECIES)\n",
    "    pivot_df.sort_index(level=0, ascending=False, inplace=True)\n",
    "    if is_plot:\n",
    "        if ax is None:\n",
    "            _, ax = plt.subplots(1)\n",
    "        _ = sns.heatmap(pivot_df, annot=True, fmt=fmt, cmap=\"coolwarm\", vmin=0, vmax=vmax,\n",
    "              annot_kws={'size': font_size}, ax=ax,\n",
    "              cbar_kws={'label': bar_label})\n",
    "        ax.figure.axes[-1].yaxis.label.set_size(font_size)\n",
    "        cbar_ticklabels = ax.figure.axes[-1].get_yticklabels()\n",
    "        ax.figure.axes[-1].set_yticklabels(cbar_ticklabels, size=font_size)\n",
    "        ax.set_title(title, size=font_size+PLOT_TITLE_FONT_INCREMENT)\n",
    "        ax.set_xlabel(\"number of species\", size=font_size)\n",
    "        ax.set_ylabel(\"number of reactions\", size=font_size)\n",
    "        xticklabels = ax.get_xticklabels()\n",
    "        ax.set_xticklabels(xticklabels, size=font_size)\n",
    "        yticklabels = ax.get_yticklabels()\n",
    "        ax.set_yticklabels(yticklabels, size=font_size)\n",
    "# Test\n",
    "heatmapCount(STRONG_DF, title=\"\", is_plot=False, is_count=True, font_size=14)\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea936995-a0c0-466d-9ec3-9027b6373a01",
   "metadata": {},
   "source": [
    "## Reference networks that induce networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8edb25-3403-4d12-84c6-7b06188f5ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    title = \"Sizes of Inducing Reference Networks\"\n",
    "    title = \"\"\n",
    "    heatmapCount(STRONG_DF, title=title, is_plot=True, network_column=cn.FINDER_REFERENCE_NETWORK,\n",
    "                 is_count=True, font_size=14)\n",
    "    path = os.path.join(cn.PLOT_DIR, \"all_reference_network_count.pdf\")\n",
    "    plt.savefig(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07810e9-2c4b-40f9-a97d-214339d69879",
   "metadata": {},
   "outputs": [],
   "source": [
    "constrained_strong_df = STRONG_DF.copy()\n",
    "# Remove small reference networks\n",
    "sel = [s > 3 and r > 3 for s, r in zip(constrained_strong_df[cn.D_NUM_SPECIES], constrained_strong_df[cn.D_NUM_REACTION])]\n",
    "CONSTRAINED_STRONG_DF = constrained_strong_df[sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188e774-05f5-4177-9e61-03a6c26ac2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    title = \"Reference Size\"\n",
    "    title = \"\"\n",
    "    heatmapCount(CONSTRAINED_STRONG_DF, title=title, is_plot=True, network_column=cn.FINDER_REFERENCE_NETWORK,\n",
    "                 is_count=True, font_size=14)\n",
    "    path = os.path.join(cn.PLOT_DIR, \"filtered_reference_network_count.pdf\")\n",
    "    plt.savefig(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7167576-b322-4fd7-9b1f-7f299ed78a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    title = \"Induced Networks per Reference Network By Reference Size\"\n",
    "    title = \"\"\n",
    "    heatmapCount(CONSTRAINED_STRONG_DF, title=title,\n",
    "                 network_column=cn.FINDER_REFERENCE_NETWORK,\n",
    "                 is_count=False, vmax=10, font_size=14,\n",
    "                 is_plot=True)\n",
    "    path = os.path.join(cn.PLOT_DIR, \"filtered_induced_network_reference.pdf\")\n",
    "    plt.savefig(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270b4cfa-c1f8-4379-a928-66d49de2cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_ALL:\n",
    "    _, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    font_size = 20\n",
    "    title = \"count of reference networks\"\n",
    "    heatmapCount(STRONG_DF, title=title, is_plot=True, network_column=cn.FINDER_REFERENCE_NETWORK,\n",
    "                 is_count=True, font_size=font_size, ax=axes[0])\n",
    "    title = \"induced network per reference network\"\n",
    "    heatmapCount(STRONG_DF, title=title,\n",
    "                 network_column=cn.FINDER_REFERENCE_NETWORK,\n",
    "                 is_count=False, vmax=10, font_size=font_size, ax=axes[1],\n",
    "                 is_plot=True)\n",
    "    path = os.path.join(cn.PLOT_DIR, \"biomodels_results.pdf\")\n",
    "    plt.savefig(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4b77d3-2b23-4fd8-a86c-20fe18c49231",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of distinct strong reference models: {len(set(STRONG_DF[cn.FINDER_REFERENCE_NAME]))}\")\n",
    "print(f\"Number of distinct weak reference models: {len(set(WEAK_DF[cn.FINDER_REFERENCE_NAME]))}\")\n",
    "print(f\"Number of distinct strong reference models processed: {len(set(FULL_STRONG_DF[cn.FINDER_REFERENCE_NAME]))}\")\n",
    "print(f\"Number of distinct weak reference models processed: {len(set(FULL_WEAK_DF[cn.FINDER_REFERENCE_NAME]))}\")\n",
    "print(f\"Number of distinct strong target models: {len(set(STRONG_DF[cn.FINDER_TARGET_NAME]))}\")\n",
    "print(f\"Number of distinct weak target models processed: {len(set(FULL_WEAK_DF[cn.FINDER_TARGET_NAME]))}\")\n",
    "print(f\"Number of distinct strong target models processed: {len(set(FULL_STRONG_DF[cn.FINDER_TARGET_NAME]))}\")\n",
    "print(f\"Number of distinct weak target models: {len(set(WEAK_DF[cn.FINDER_TARGET_NAME]))}\")\n",
    "print(f\"Number of strong pairs evaluated: {len(FULL_STRONG_DF)}\")\n",
    "print(f\"Number of weak pairs evaluated: {len(FULL_WEAK_DF)}\")\n",
    "print(f\"Number of strong induced subnsets: {len(STRONG_DF)}\")\n",
    "print(f\"Number of weak induced subnsets: {len(WEAK_DF)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ee5ab-7a60-450c-b8ea-3a8c58757167",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    heatmapPOC(STRONG_DF, 'probability_of_occurrence_strong_induced', title=\"Strong, Induced, POC\", is_plot=True)\n",
    "    plt.figure()\n",
    "    heatmapPOC(WEAK_DF, 'probability_of_occurrence_strong_induced', title=\"Weak, Induced, POC\", is_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a019a1a7-e210-417e-896d-8858ca68974c",
   "metadata": {},
   "source": [
    "## Target networks with induced networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0ece6-50c5-42ef-948a-02732eea3c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_df = CONSTRAINED_STRONG_DF[[cn.FINDER_REFERENCE_NAME, cn.FINDER_TARGET_NAME]]\n",
    "strong_df = strong_df.merge(SUMMARY_DF, right_on='model_name', left_on='target_name')\n",
    "strong_df = strong_df[[cn.FINDER_REFERENCE_NAME, cn.FINDER_TARGET_NAME, cn.D_NUM_REACTION, cn.D_NUM_SPECIES]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e762118-6097-41f3-9c8b-ce883c08189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    title = \"Target Sizes\"\n",
    "    title = \"\"\n",
    "    heatmapCount(strong_df, title=title, is_plot=True, network_column=cn.FINDER_TARGET_NAME,\n",
    "                 is_count=True, vmax=5)\n",
    "    path = os.path.join(cn.PLOT_DIR, \"target_network_count.pdf\")\n",
    "    plt.savefig(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90726c62-da47-4710-a3f7-969797607b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    title = \"Induced Networks per Target Network By Target Size\"\n",
    "    title = \"\"\n",
    "    heatmapCount(strong_df, title=title, network_column=cn.FINDER_TARGET_NAME,\n",
    "                 is_count=False, vmax=5, fmt=\"1.0f\",\n",
    "                 is_plot=True)\n",
    "    path = os.path.join(cn.PLOT_DIR, \"induced_network_target.pdf\")\n",
    "    plt.savefig(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f031d30f-e407-4a34-b9f0-46aa9b4781b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weak vs. Strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f554601-b3a9-4db0-9d6d-f51eff4d09fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(STRONG_DF), len(WEAK_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4190e183-2a78-4acf-88bf-a3f2d1c62e0c",
   "metadata": {},
   "source": [
    "# Reference network details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee53cf-ddaa-431a-ae60-6d5c4394b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all of the reference models that appear in targets\n",
    "names = list(set(CONSTRAINED_STRONG_DF[cn.FINDER_REFERENCE_NAME]))\n",
    "names = list(set(STRONG_DF[cn.FINDER_REFERENCE_NAME]))\n",
    "names.sort()\n",
    "print(f\"Number of distinct networks: {len(names)}\\n\")\n",
    "for name in names:\n",
    "    result = makeAntimony(name)\n",
    "    if result is not None:\n",
    "        print(result + '\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
